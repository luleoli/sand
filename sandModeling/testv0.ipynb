{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82d37ea",
   "metadata": {},
   "source": [
    "# First test of the modeling part of the pipeline: responsible for creating the model\n",
    "Notebook structure (recommended)\n",
    "2. Data loading: load preprocessed datasets and metadata.\n",
    "4. Model: define, train, persist.\n",
    "5. Evaluation: compute and save metrics and plots.\n",
    "6. Save artifacts: model, transformers, metrics, config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf55897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('../data/churn/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a524370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the specific dates range\n",
    "start_date = \"2023-06-01\"\n",
    "end_date = \"2023-09-30\"\n",
    "\n",
    "safra = []\n",
    "# Generate a random date within the specified range\n",
    "for i in range(df_train.shape[0]):\n",
    "    safra.append(\n",
    "        pd.to_datetime(\n",
    "            np.random.choice(pd.date_range(start=start_date, end=end_date))\n",
    "        ).strftime(\"%Y%m\")\n",
    "    )\n",
    "\n",
    "df_train[\"safra\"] = safra\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "n_ones = int(round(0.2 * len(df_train)))\n",
    "\n",
    "df_train['no_action'] = 0\n",
    "df_train.loc[rng.choice(df_train.index, size=n_ones, replace=False), 'no_action'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c0c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oot = df_train[df_train['safra'] == '202309']\n",
    "df_train = df_train[df_train['safra'] != '202309']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b17e6",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Mdl Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "280c841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_parameters = {\n",
    "    'description_general': '''\n",
    "\n",
    "    <div style=\"display:grid; grid-template-columns:300px 1fr; gap:8px 16px; align-items:start;\">\n",
    "        <div class=\"txt-hg-blue\">Projeto:</div>\n",
    "        <div class=\"txt-hg-bold\">Ariel - Concessão de Crédito Rotativo</div>\n",
    "\n",
    "        <div class=\"txt-hg-blue\">Objetivo:</div>\n",
    "        <div>Desenvolver modelo auxiliar target na tomada de decisão.</div>\n",
    "\n",
    "        <div class=\"txt-hg-blue\">Target:</div>\n",
    "        <div><span style=\"background:#ffe8e0; color:#7a2b15; padding:3px 8px; border-radius:12px; font-weight:600;\">Over 60 Mob 6</span></div>\n",
    "\n",
    "        <div class=\"txt-hg-blue\">Período de Treinamento:</div>\n",
    "        <div>2024-06 a 2024-08</div>\n",
    "\n",
    "        <div class=\"txt-hg-blue\">Período de OOT:</div>\n",
    "        <div>2024-09 a 2024-10</div>\n",
    "\n",
    "        <div class=\"txt-hg-blue\">Métricas de Avaliação:</div>\n",
    "        <div>Gini Coefficient, % Alto Risco Target, % Baixo Risco Não Target</div>\n",
    "      </div>\n",
    "\n",
    "    ''',\n",
    "    'target_obs': 'no_action',\n",
    "    'target_obs_inf': 'no_action',\n",
    "    'no_action_var': 'no_action',\n",
    "    'date_var': 'safra',\n",
    "    'date_oot': ['202406', '202407', '202408'],\n",
    "    'features_excluded': ['ID', 'safra', 'no_action'],\n",
    "    'mdls': [],\n",
    "    'target_mdl': '',\n",
    "    'categorical_features': [],\n",
    "    'description_specific': '',\n",
    "    'model_name': '',\n",
    "    'tbl_version': '',\n",
    "    'inf_version': '',\n",
    "    'mdl_version': '',\n",
    "}\n",
    "\n",
    "\n",
    "pipeline_parameters['description_specific'] = 'Modelo inicial sem seleção de features e sem otimizacao de parametros.'\n",
    "\n",
    "pipeline_parameters['tbl_version'] = 'ariel_tbl_0_0_1'\n",
    "pipeline_parameters['inf_version'] = 'ariel_inf_0_0_1'\n",
    "pipeline_parameters['mdl_version'] = 'sand_0_0_1'\n",
    "\n",
    "pipeline_parameters['model_name'] = 'ariel_mdl_0_0_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8cf4759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21088, number of negative: 78463\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 99551, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211831 -> initscore=-1.313923\n",
      "[LightGBM] [Info] Start training from score -1.313923\n",
      "Validation AUC: 0.8895\n",
      "Validation Accuracy: 0.8664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8903    0.9471    0.9178     19616\n",
      "           1     0.7420    0.5658    0.6421      5272\n",
      "\n",
      "    accuracy                         0.8664     24888\n",
      "   macro avg     0.8162    0.7565    0.7800     24888\n",
      "weighted avg     0.8589    0.8664    0.8594     24888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Train a LightGBM classifier for churn prediction (new notebook cell)\n",
    "\n",
    "\n",
    "# feature setup: drop identifiers and text surname\n",
    "drop_cols = ['id', 'CustomerId', 'Surname', 'safra', 'no_action']\n",
    "target = 'Exited'\n",
    "\n",
    "X = df_train.drop(columns=drop_cols + [target])\n",
    "y = df_train[target]\n",
    "\n",
    "# mark categorical features so LightGBM can handle them natively\n",
    "for c in ['Geography', 'Gender']:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "    if c in df_train.columns:\n",
    "        df_train[c] = df_train[c].astype('category')\n",
    "\n",
    "# train/validation split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# model\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# fit with early stopping\n",
    "model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='auc',\n",
    "    categorical_feature=['Geography', 'Gender']\n",
    ")\n",
    "\n",
    "\n",
    "# validation metrics\n",
    "val_probs = model.predict_proba(X_val)[:, 1]\n",
    "val_preds = (val_probs >= 0.5).astype(int)\n",
    "print(\"Validation AUC:\", round(roc_auc_score(y_val, val_probs), 4))\n",
    "print(\"Validation Accuracy:\", round(accuracy_score(y_val, val_preds), 4))\n",
    "print(classification_report(y_val, val_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb070e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21088, number of negative: 78463\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1114\n",
      "[LightGBM] [Info] Number of data points in the train set: 99551, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211831 -> initscore=-1.313923\n",
      "[LightGBM] [Info] Start training from score -1.313923\n",
      "Validation AUC: 0.894\n",
      "Validation Accuracy: 0.868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8912    0.9483    0.9188     19616\n",
      "           1     0.7474    0.5690    0.6461      5272\n",
      "\n",
      "    accuracy                         0.8680     24888\n",
      "   macro avg     0.8193    0.7587    0.7825     24888\n",
      "weighted avg     0.8607    0.8680    0.8611     24888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Train a LightGBM classifier for churn prediction (new notebook cell)\n",
    "\n",
    "\n",
    "# feature setup: drop identifiers and text surname\n",
    "drop_cols = ['id', 'CustomerId', 'Surname', 'safra', 'no_action']\n",
    "target = 'Exited'\n",
    "\n",
    "X = df_train.drop(columns=drop_cols + [target])\n",
    "y = df_train[target]\n",
    "\n",
    "# mark categorical features so LightGBM can handle them natively\n",
    "for c in ['Geography', 'Gender']:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "    if c in df_train.columns:\n",
    "        df_train[c] = df_train[c].astype('category')\n",
    "\n",
    "# train/validation split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=32, stratify=y)\n",
    "\n",
    "# model\n",
    "model2 = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# fit with early stopping\n",
    "model2.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='auc',\n",
    "    categorical_feature=['Geography', 'Gender']\n",
    ")\n",
    "\n",
    "\n",
    "# validation metrics\n",
    "val_probs = model2.predict_proba(X_val)[:, 1]\n",
    "val_preds = (val_probs >= 0.5).astype(int)\n",
    "print(\"Validation AUC:\", round(roc_auc_score(y_val, val_probs), 4))\n",
    "print(\"Validation Accuracy:\", round(accuracy_score(y_val, val_preds), 4))\n",
    "print(classification_report(y_val, val_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2164cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['model_score'] = model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76fc652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['model_score2'] = model2.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87cff7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22313/1868754742.py:17: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: gini_from_scores(g[target], g[mdl]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safra</th>\n",
       "      <th>gini_model_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202306</td>\n",
       "      <td>79.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202307</td>\n",
       "      <td>79.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202308</td>\n",
       "      <td>79.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    safra  gini_model_score\n",
       "0  202306             79.57\n",
       "1  202307             79.20\n",
       "2  202308             79.42"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini_from_scores(y_true, y_score):\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    return 2 * auc - 1\n",
    "\n",
    "mdls = ['model_score']\n",
    "\n",
    "# Gini per safra\n",
    "\n",
    "gini_per_safra = pd.DataFrame()\n",
    "\n",
    "for mdl in mdls:\n",
    "    gini_safra = (\n",
    "        df_train.groupby(\"safra\")\n",
    "        .apply(lambda g: gini_from_scores(g[target], g[mdl]))\n",
    "        .reset_index()\n",
    "        .rename(columns={0: f\"gini_{mdl}\"})\n",
    "    )\n",
    "    if gini_per_safra.empty:\n",
    "        gini_per_safra = gini_safra\n",
    "    else:\n",
    "        gini_per_safra = gini_per_safra.merge(gini_safra, on=\"safra\")\n",
    "\n",
    "        \n",
    "    gini_per_safra[f\"gini_{mdl}\"] = (gini_per_safra[f\"gini_{mdl}\"] * 100).round(2)\n",
    "\n",
    "\n",
    "gini_per_safra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa7c5af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gini_model_score']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16f9dc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7a0679141ff747f7af683450cc4eace3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7a0679141ff747f7af683450cc4eace3.vega-embed details,\n",
       "  #altair-viz-7a0679141ff747f7af683450cc4eace3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7a0679141ff747f7af683450cc4eace3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7a0679141ff747f7af683450cc4eace3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7a0679141ff747f7af683450cc4eace3\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@6?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@6.1.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@7?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"6\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"6.1.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"7\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"safra\", \"sort\": \"ascending\", \"title\": \"Safra\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"labels\": false}, \"field\": \"gini_model_score\", \"scale\": {\"domain\": [74.2, 84.57], \"nice\": true}, \"title\": \"Gini\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"color\": \"black\", \"dy\": -10}, \"encoding\": {\"text\": {\"field\": \"gini_model_score\", \"format\": \".1f\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"safra\", \"sort\": \"ascending\", \"type\": \"nominal\"}, \"y\": {\"field\": \"gini_model_score\", \"scale\": {\"domain\": [74.2, 84.57], \"nice\": true}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-e2c561fd01786c92da20265da4463238\"}, \"height\": 250, \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v6.1.0.json\", \"datasets\": {\"data-e2c561fd01786c92da20265da4463238\": [{\"safra\": \"202306\", \"gini_model_score\": 79.57}, {\"safra\": \"202307\", \"gini_model_score\": 79.2}, {\"safra\": \"202308\", \"gini_model_score\": 79.42}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "gini_cols = [c for c in gini_per_safra.columns if c.startswith(\"gini_\")]\n",
    "y_max = gini_per_safra[gini_cols].max(axis=0).values.max()\n",
    "y_min = gini_per_safra[gini_cols].min(axis=0).values.min()\n",
    "\n",
    "y_scale = alt.Scale(domain=[max(0, y_min - 5), y_max + 5], nice=True)\n",
    "\n",
    "line = (\n",
    "    alt.Chart(gini_per_safra)\n",
    "    .mark_line(point=True)\n",
    "    .encode(\n",
    "        x=alt.X(\"safra:N\", title=\"Safra\", sort=\"ascending\", axis=alt.Axis(labelAngle=-45)),\n",
    "        y=alt.Y(\"gini_model_score:Q\", title=\"Gini\", scale=y_scale, axis=alt.Axis(labels=False)),\n",
    "    )\n",
    ")\n",
    "\n",
    "labels = (\n",
    "    alt.Chart(gini_per_safra)\n",
    "    .mark_text(align=\"center\", dy=-10, color=\"black\")\n",
    "    .encode(\n",
    "        x=alt.X(\"safra:N\", sort=\"ascending\"),\n",
    "        y=alt.Y(\"gini_model_score:Q\", scale=y_scale),\n",
    "        text=alt.Text(\"gini_model_score:Q\", format=\".1f\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "chart_line = (line + labels).properties(width=200, height=250)\n",
    "\n",
    "chart_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c5f98ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22313/4072508001.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({f\"gini_{m}\": gini_from_scores(g[target], g[m]) for m in mdls}))\n",
      "/tmp/ipykernel_22313/4072508001.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({f\"gini_{m}\": gini_from_scores(g[target], g[m]) for m in mdls}))\n",
      "/tmp/ipykernel_22313/4072508001.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({f\"gini_{m}\": gini_from_scores(g[target], g[m]) for m in mdls}))\n"
     ]
    }
   ],
   "source": [
    "# build gini per safra for both models and plot them on the same chart\n",
    "mdls = ['model_score', 'model_score2']\n",
    "\n",
    "def create_gini_chart(df_train, target, mdls):\n",
    "        \n",
    "    # compute gini per safra for each model\n",
    "    gini_per_safra = (\n",
    "        df_train.groupby(\"safra\")\n",
    "        .apply(lambda g: pd.Series({f\"gini_{m}\": gini_from_scores(g[target], g[m]) for m in mdls}))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    for col in [f\"gini_{m}\" for m in mdls]:\n",
    "        gini_per_safra[col] = (gini_per_safra[col] * 100).round(2)\n",
    "\n",
    "    # long format for Altair\n",
    "    gini_long = gini_per_safra.melt(id_vars=\"safra\", value_vars=[f\"gini_{m}\" for m in mdls],\n",
    "                                    var_name=\"model\", value_name=\"gini\")\n",
    "\n",
    "    # y scale domain\n",
    "    y_max = gini_long[\"gini\"].max()\n",
    "    y_min = gini_long[\"gini\"].min()\n",
    "    y_scale = alt.Scale(domain=[max(0, y_min - 5), y_max + 5], nice=True)\n",
    "    # line + points per model with legend\n",
    "    line = (\n",
    "        alt.Chart(gini_long)\n",
    "        .mark_line(point=True)\n",
    "        .encode(\n",
    "            x=alt.X(\"safra:N\", title=\"Safra\", sort=\"ascending\", axis=alt.Axis(labelAngle=-45)),\n",
    "            y=alt.Y(\"gini:Q\", title=\"Gini\", scale=y_scale),\n",
    "            color=alt.Color(\"model:N\", title=\"Model\", legend=alt.Legend(orient=\"bottom\")),\n",
    "            tooltip=[\"safra\", \"model\", alt.Tooltip(\"gini:Q\", format=\".2f\")],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # labels on points (no legend duplication) with smaller font\n",
    "    labels = (\n",
    "        alt.Chart(gini_long)\n",
    "        .mark_text(align=\"center\", dy=-10, fontSize=9)\n",
    "        .encode(\n",
    "            x=alt.X(\"safra:N\", sort=\"ascending\"),\n",
    "            y=alt.Y(\"gini:Q\", scale=y_scale),\n",
    "            text=alt.Text(\"gini:Q\", format=\".1f\"),\n",
    "            color=alt.Color(\"model:N\", legend=None),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    (chart := (line + labels).properties(width=200, height=150))\n",
    "    return chart\n",
    "\n",
    "gini_obs_graph = create_gini_chart(df_train, target='Exited', mdls=mdls)\n",
    "gini_obs_inf_graph = create_gini_chart(df_train, target='Exited', mdls=mdls)\n",
    "\n",
    "temp = df_train[df_train['no_action'] == 1]\n",
    "\n",
    "gini_no_action_graph = create_gini_chart(temp, target='Exited', mdls=mdls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9fe9dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_obs_graph_json = gini_obs_graph.to_json()\n",
    "gini_obs_inf_graph_json = gini_obs_inf_graph.to_json()\n",
    "gini_no_action_graph_json = gini_no_action_graph.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "90b3e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_train = round(gini_from_scores(df_train['Exited'], df_train['model_score']) * 100, 2)\n",
    "df_val = df_train[df_train.index.isin(X_val.index)]\n",
    "gini_test = round(gini_from_scores(df_val['Exited'], model.predict_proba(df_val[model.feature_names_in_])[:, 1]) * 100, 2)\n",
    "\n",
    "\n",
    "# mark categorical features so LightGBM can handle them natively\n",
    "for c in ['Geography', 'Gender']:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "    if c in df_oot.columns:\n",
    "        df_oot[c] = df_oot[c].astype('category')\n",
    "\n",
    "gini_oot = round(gini_from_scores(df_oot['Exited'], model.predict_proba(df_oot[model.feature_names_in_])[:, 1]) * 100, 2)\n",
    "gini_no_action = round(gini_from_scores(df_train[df_train['no_action'] == 1]['Exited'], df_train[df_train['no_action'] == 1]['model_score']) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a8980",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.1 Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "588b2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### JINJA TEMPLATE\n",
    "import os\n",
    "from jinja2 import Template\n",
    "\n",
    "# Read the template from the template sheet\n",
    "template_path = \"../sandMdlLog/MdlLog_template.html\"\n",
    "with open(template_path, \"r\") as file:\n",
    "    sanEda_mdl_template = file.read()\n",
    "\n",
    "# Create a Jinja2 template object\n",
    "\n",
    "template = Template(sanEda_mdl_template)\n",
    "\n",
    "# Render the template with the data\n",
    "rendered_html = template.render(\n",
    "    title=pipeline_parameters['model_name'],\n",
    "    description_general = pipeline_parameters['description_general'],\n",
    "    description_specific = pipeline_parameters['description_specific'],\n",
    "    tbl_version = pipeline_parameters['tbl_version'],\n",
    "    inf_version = pipeline_parameters['inf_version'],\n",
    "    mdl_version = pipeline_parameters['mdl_version'],\n",
    "    init_params_txt = str(pipeline_parameters),\n",
    "    tgt_neg_criteria = '10',\n",
    "    ntgt_aprv_criteria = '2',\n",
    "    gini_obs_graph_json = gini_obs_graph_json,\n",
    "    gini_obs_inf_graph_json = gini_obs_inf_graph_json,\n",
    "    gini_no_action_graph_json = gini_no_action_graph_json,\n",
    "    gini_train = gini_train,\n",
    "    gini_test = gini_test,\n",
    "    gini_oot = gini_oot,\n",
    "    gini_noaction = gini_no_action\n",
    ")\n",
    "\n",
    "# Save the rendered HTML to a file\n",
    "with open(f\"report_{pipeline_parameters['model_name']}.html\", \"w\") as file:\n",
    "    file.write(rendered_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed0c2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(self, report_version: str):\n",
    "    ### OVERVIEW\n",
    "\n",
    "    sandeda = SandEDA(\n",
    "        self.df, self.target_name, self.time_name, self.id_name, self.top_n\n",
    "    )\n",
    "    res_general = sandeda.calc_general()\n",
    "\n",
    "    overview_target_metric_time = res_general[\"target_general\"][\n",
    "        \"target_metric_time\"\n",
    "    ]\n",
    "\n",
    "    # Create the bar plot using Altair\n",
    "    chart = (\n",
    "        alt.Chart(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Date\": list(overview_target_metric_time.keys()),\n",
    "                    \"%\": list(overview_target_metric_time.values()),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        .mark_bar()\n",
    "        .encode(x=alt.X(\"Date\", sort=\"ascending\"), y=alt.Y(\"%\"))\n",
    "        .properties(width=100, height=100)\n",
    "        .configure_axis(labelAngle=45)\n",
    "        .configure_title(fontSize=10)\n",
    "    )\n",
    "\n",
    "    overview_tab_general = pd.DataFrame(\n",
    "        list(res_general[\"dataset_general\"].items()),\n",
    "        columns=[\"Description\", \"Value\"],\n",
    "        index=None,\n",
    "    )\n",
    "    overview_tab_general[\"Value\"] = overview_tab_general[\"Value\"].apply(\n",
    "        lambda x: f\"{x:,.0f}\")\n",
    "    overview_tab_general = overview_tab_general.to_html(index=False, border=0)\n",
    "\n",
    "    overview_tab_full = pd.DataFrame(res_general[\"missing_zero\"]).to_html(\n",
    "        index=False, border=0\n",
    "    )\n",
    "\n",
    "    overview_target_name = res_general[\"target_general\"][\"target_name\"]\n",
    "\n",
    "    overview_target_metric = round((\n",
    "        res_general[\"target_general\"][\"number_of_one\"]\n",
    "        / (\n",
    "            res_general[\"target_general\"][\"number_of_zero\"]\n",
    "            + res_general[\"target_general\"][\"number_of_one\"]\n",
    "        )\n",
    "    ) * 100, 2)\n",
    "\n",
    "    overview_tgt_graph_json = chart.to_json()\n",
    "\n",
    "    ### VARIABLES\n",
    "\n",
    "    iv_, mi_ = sandeda.promising_features()\n",
    "    psi_, ks_ = sandeda.variables_estability()\n",
    "    miss_, zero_ = sandeda.variables_fillment()\n",
    "\n",
    "    var_tab_ks = pd.DataFrame(\n",
    "        {\n",
    "        \"Variable\": [var for var, _ in ks_],\n",
    "        \"KS\": [round(max(value.values()), 3) for _, value in ks_],\n",
    "        }\n",
    "    ).to_html(index=False, border=0)\n",
    "\n",
    "    var_tab_psi = pd.DataFrame(\n",
    "        {\n",
    "            \"Variable\": [var for var, _ in psi_],\n",
    "            \"PSI\": [round(max(value.values()), 3) for _, value in psi_],\n",
    "        }\n",
    "    ).to_html(index=False, border=0)\n",
    "\n",
    "    var_tab_iv = pd.DataFrame(\n",
    "        {\"Variable\": [var for var, _ in iv_], \"IV\": [round(value, 3) for _, value in iv_]}\n",
    "    ).to_html(index=False, border=0)\n",
    "\n",
    "    var_tab_mi = pd.DataFrame(\n",
    "        {\"Variable\": [var for var, _ in mi_], \"MI\": [round(value, 3) for _, value in mi_]}\n",
    "    ).to_html(index=False, border=0)\n",
    "\n",
    "    var_tab_miss = pd.DataFrame(miss_).to_html(index=False, border=0)\n",
    "    var_tab_zero = pd.DataFrame(zero_).to_html(index=False, border=0)\n",
    "\n",
    "    ### ESPECIFIC VARIABLES\n",
    "\n",
    "    variables_espec = sandeda.variables_espec()\n",
    "\n",
    "    variables_espec_time = sandeda.variables_espec_time()\n",
    "\n",
    "    var_espec_content = {}\n",
    "\n",
    "    vars_keys = variables_espec.keys() - {\n",
    "        self.id_name,\n",
    "        self.target_name,\n",
    "        self.time_name,\n",
    "    }\n",
    "\n",
    "    for var_espec in vars_keys:\n",
    "        hist_var = variables_espec[var_espec][\"histogram\"]\n",
    "\n",
    "        decil_var = variables_espec[var_espec][\"decil\"]\n",
    "\n",
    "        del (\n",
    "            variables_espec[var_espec][\"histogram\"],\n",
    "            variables_espec[var_espec][\"decil\"],\n",
    "        )\n",
    "\n",
    "        var_spec_tab_desc = pd.DataFrame(\n",
    "            {\n",
    "                \"Description\": variables_espec[var_espec][\n",
    "                    \"descriptive_statistics\"\n",
    "                ].keys(),\n",
    "                \"Value\": [\n",
    "                    f\"{value:,.0f}\" if isinstance(value, (int, float)) else str(value) for value in variables_espec[var_espec][\n",
    "                        \"descriptive_statistics\"\n",
    "                    ].values()\n",
    "                ],\n",
    "            }\n",
    "        ).to_html(index=False, border=0)\n",
    "\n",
    "        var_spec_tab_quant = pd.DataFrame(\n",
    "            {\n",
    "                \"Description\": variables_espec[var_espec][\n",
    "                    \"quantile_statistics\"\n",
    "                ].keys(),\n",
    "                \"Value\": [\n",
    "                    f\"{value:,.0f}\" if isinstance(value, (int, float)) else str(value) for value in variables_espec[var_espec][\n",
    "                        \"quantile_statistics\"\n",
    "                    ].values()\n",
    "                ],\n",
    "            }\n",
    "        ).to_html(index=False, border=0)\n",
    "\n",
    "        if variables_espec[var_espec][\"descriptive_statistics\"][\n",
    "            \"number_of_unique_values\"\n",
    "        ] <= 50 or variables_espec[var_espec][\"descriptive_statistics\"][\n",
    "            \"variable_type\"\n",
    "        ] not in [\"int64\", \"float64\"]:\n",
    "            # Convert the histogram data to a dataframe\n",
    "            hist_data = pd.DataFrame(\n",
    "                {\n",
    "                    \"Interval\": list(hist_var.keys()),\n",
    "                    \"Count\": list(hist_var.values()),\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            hist_data = pd.DataFrame(\n",
    "                {\n",
    "                    \"Interval\": [\n",
    "                        f\"{interval.left:.1f}\" for interval in hist_var.keys()\n",
    "                    ],\n",
    "                    \"Count\": list(hist_var.values()),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Create the bar plot using Altair\n",
    "        hist_chart = (\n",
    "            alt.Chart(hist_data)\n",
    "            .mark_bar()\n",
    "            .encode(\n",
    "                x=alt.X(\n",
    "                    \"Interval\",\n",
    "                    title=\"\",\n",
    "                    sort=None,\n",
    "                    axis=alt.Axis(labels=True, labelOverlap=True, labelFontSize=9),\n",
    "                ),\n",
    "                y=alt.Y(\"Count\", title=\"Qty\", axis=alt.Axis(labels=False)),\n",
    "            )\n",
    "            .properties(width=350, height=200, title=\"Histogram\")\n",
    "            .configure_axis(labelAngle=45)\n",
    "            .configure_title(fontSize=14)\n",
    "            .interactive(False)\n",
    "        )  # Disable interactive features\n",
    "\n",
    "        var_spec_hist_graph_json = hist_chart.to_json()\n",
    "\n",
    "        decil_data = pd.DataFrame(\n",
    "            {\"Decil\": list(decil_var.index), \"Target\": list(np.round(decil_var.values, 2))}\n",
    "        )\n",
    "\n",
    "        # Create the bar plot using Altair\n",
    "        decil_chart = (\n",
    "            alt.Chart(decil_data)\n",
    "            .mark_bar()\n",
    "            .encode(\n",
    "                x=alt.X(\n",
    "                    \"Decil\",\n",
    "                    title=\"Decil\",\n",
    "                    sort=None,\n",
    "                    axis=alt.Axis(labels=True, labelOverlap=True, labelFontSize=9),\n",
    "                ),\n",
    "                y=alt.Y(\"Target\", title=\"% Target\", axis=alt.Axis(labels=False)),\n",
    "            )\n",
    "            .properties(width=350, height=200, title=\"Target mean per Decil\")\n",
    "            .configure_axis(labelAngle=45)\n",
    "            .configure_title(fontSize=12)\n",
    "            .interactive(False)\n",
    "        )  # Disable interactive features\n",
    "\n",
    "        var_spec_decil_graph_json = decil_chart.to_json()\n",
    "\n",
    "        # Create a dataframe with the number_per_quintile values for each time period\n",
    "        df_quintile_time = pd.DataFrame(\n",
    "            {\n",
    "                \"Date\": list(variables_espec_time[var_espec].keys()),\n",
    "                \"number_per_quintile\": [\n",
    "                    variables_espec_time[var_espec][date][\"number_per_quintile\"]\n",
    "                    for date in variables_espec_time[var_espec].keys()\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Expand the number_per_quintile dictionary into separate columns\n",
    "        df_quintile_time = df_quintile_time.join(\n",
    "            pd.DataFrame(\n",
    "                df_quintile_time.pop(\"number_per_quintile\").tolist(),\n",
    "                index=df_quintile_time.index,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Melt the dataframe to have a long format suitable for Altair\n",
    "        df_melted = df_quintile_time.melt(\n",
    "            id_vars=\"Date\", var_name=\"Quintile\", value_name=\"Count\"\n",
    "        )\n",
    "\n",
    "        # Calculate the percentage for each quintile\n",
    "        df_melted[\"Percentage\"] = df_melted.groupby(\"Date\")[\"Count\"].transform(\n",
    "            lambda x: x / x.sum() * 100\n",
    "        )\n",
    "\n",
    "        # Create the 100% stacked column chart using Altair\n",
    "        stacked_chart = (\n",
    "            alt.Chart(df_melted)\n",
    "            .mark_bar()\n",
    "            .encode(\n",
    "                x=alt.X(\"Date\", title=\"Date\"),\n",
    "                y=alt.Y(\"Percentage\", title=\"Percentage\", stack=\"normalize\"),\n",
    "                color=alt.Color(\"Quintile\", title=\"Legend\"),\n",
    "            )\n",
    "            .properties(width=800, height=200, title=\"Distribution Over Time\")\n",
    "            .configure_axis(labelAngle=45)\n",
    "            .configure_title(fontSize=14)\n",
    "            .configure_legend(orient=\"top\")\n",
    "            .interactive(False)\n",
    "        )  # Disable interactive features\n",
    "\n",
    "        var_spec_stacked_graph_json = stacked_chart.to_json()\n",
    "\n",
    "        var_espec_content[var_espec] = {\n",
    "            \"tab_desc\": var_spec_tab_desc,\n",
    "            \"tab_quant\": var_spec_tab_quant,\n",
    "            \"hist\": var_spec_hist_graph_json,\n",
    "            \"decil\": var_spec_decil_graph_json,\n",
    "            \"hist_time\": var_spec_stacked_graph_json,\n",
    "        }\n",
    "\n",
    "    ### JINJA TEMPLATE\n",
    "\n",
    "    # Read the template from the template sheet\n",
    "    template_path = os.path.join(os.path.dirname(__file__), \"./template/sandEda_template.html\")\n",
    "    with open(template_path, \"r\") as file:\n",
    "        sanEda_template = file.read()\n",
    "\n",
    "    # Create a Jinja2 template object\n",
    "\n",
    "    template = Template(sanEda_template)\n",
    "\n",
    "    # Render the template with the data\n",
    "    rendered_html = template.render(\n",
    "        title=report_version,\n",
    "        overview_tab_general=overview_tab_general,\n",
    "        overview_tab_full=overview_tab_full,\n",
    "        overview_target_metric=overview_target_metric,\n",
    "        overview_target_name=overview_target_name,\n",
    "        overview_tgt_graph_json=overview_tgt_graph_json,\n",
    "        var_tab_iv=var_tab_iv,\n",
    "        var_tab_mi=var_tab_mi,\n",
    "        var_tab_miss=var_tab_miss,\n",
    "        var_tab_zero=var_tab_zero,\n",
    "        var_tab_psi=var_tab_psi,\n",
    "        var_tab_ks=var_tab_ks,\n",
    "        specific_variables=var_espec_content,\n",
    "    )\n",
    "\n",
    "    # Save the rendered HTML to a file\n",
    "    with open(f\"SandEDA_{report_version}.html\", \"w\") as file:\n",
    "        file.write(rendered_html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
